### Minimum Description Length for Universal Science

Someone is broadcasting a stream of bits. You don't know why. A 500-bit-long sample looks like this:

```
01100110110101011011111100001001110000100011010001101011011010000001010000001010
10100111101000101111010100100101010010101010101000010100110101010011111111010101
01010101011111110101011010101101111101010110110101010100000001101111100000111010
11100000000000001111101010110101010101001010101101010101100111001100001100110101
11111111111111111100011001011010011010101010101100000010101011101101010010110011
11111010111101110100010101010111001111010001101101010101101011000101100000101010
10011001101010101111...
```

The thought occurs to you to [do Science to it](http://dresdencodak.com/2008/05/02/copan/)—to ponder if there's some way you could better [predict](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences) what bits are going to come next. At first you might think that you can't—it's just a bunch of random bits. You can't predict it because that's what random _means_.

Or does it? True, if the sequence represented flips of a fair coin—every flip independently landing either `0` or `1` with exactly equal probability—then there would be no way you could predict what would come next: any continuation you could posit would be exactly as probable as any other.

But if the sequence represented flips of a _biased_ coin—if, say, `1` came up 0.55 of the time instead of exactly 0.5—then it would be possible to predict better or worse. Your [best bet for the next bit in isolation would always be `1`](https://www.lesswrong.com/posts/msJA6B9ZjiiZxT6EZ/lawful-uncertainty), and you would more strongly anticipate sequences with slightly more `1`s than `0`s.

You count 265 `1`s in the sample of 500 bits. _Given_ the hypothesis that the bits were generated by a fair coin, the number of `1`s (or without loss of generality, `0`s) would be given by the binomial distribution ${500\choose k} (0.5)^k (0.5)^{500-k}$, which [has a standard deviation of](https://en.wikipedia.org/wiki/Binomial_distribution) $\sqrt{500 \cdot 0.5^2} = \sqrt{125} \approx 11.18$, so your observation of $265 - 250 = 15$ excess `1`s is about $15/11.18 \approx 1.34$ standard deviations from the mean—not out of the realm of plausibility of happening by chance, although you're certainly _suspicious_ that the coin behind these bits isn't quite fair.

... that is, if it's even a coin. You love talking in terms of shiny, if hypothetical, "coins" rather than stodgy old "[independent and identically distributed](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) binary-valued random variables", but looking at the sample again, you begin to _further_ doubt whether the bits are independent of each other. You've [heard that humans are biased](https://www.lesswrong.com/posts/6xGC9P8wp2mi7uhti/inaccessible-finely-tuned-rng-in-humans) to overestimate the frequency of alternations (`101010`...) and underestimate the frequency of consecutive runs (`00000`... or `11111`...) in "truly" (uniformly) random data, but the 500-bit sample contains a run of 13 `0`s (starting at position 243) _and_ a run of 19 `1`s (starting at position 319). You're not immediately sure how to [calculate](http://www.gregegan.net/QUARANTINE/Runs/Runs.html) the [probability](https://www.johndcook.com/blog/2012/11/14/probability-of-long-runs/) of that, but your gut says that should be very unlikely given the biased-coin model, even after taking into account that human guts aren't very good at estimating these things.

Maybe not everything in the universe is a coin. What if the bits were being generated by a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain)—if the probability of the next bit depended on the value of the one just before? If a `0` made the _next_ bit more likely to be a `0`, and the same for `1`, that would make the `00000`... and `11111`... runs less improbable.

Except ... the sample _also_ has a run of 17 alternations (starting at position 153). On the "fair coin" model, that should be $2^{17-13} = 16$ times as suspicious as the run of 13 `0`s and $2^{17-19} = \frac{1}{4}$ as suspicious as the run of 19 `1`s which led you to hypothesize a Markov chain. But a Markov chain in which a `0` or `1` makes another of the same more likely, makes alternations _less_ likely: the Markov chain hypothesis can only make the consecutive runs look less surprising at the expense of making the run of alternations look _more_ surprising.

So maybe it's all just a coincidence: the broadcast is random—whatever that means—and you're just pattern-matching on noise. Unless ...

Could it be that some things in the universe are _neither_ coins _nor_ Markov chains? You don't _know_ who is broadcasting these bits or why; you called it "random" because you didn't see any obvious pattern, but now that you think about it, it would be pretty weird for someone to just be broadcasting random bits. Probably the broadcast is a movie or a stock ticker; if a close-up sample of the individual bits looks "random", that's only because you don't know the [codec](https://en.wikipedia.org/wiki/Codec).

Trying to guess a video codec is [_obviously_ impossible](https://www.lesswrong.com/posts/5wMcKNAwB6X4mp9og/that-alien-message). Does that kill all hope of being able to better predict future bits? _Maybe_ not. Even if you don't know what the broadcast is really for, there might be some nontrivial _local_ structure to it, where bits are statistically related to the bits nearby, like how a dumb encoding of a video might have consecutive runs of the same bit where a large portion of a frame is the same color, like the sky.

Local structure, where bits are statistically related to the bits nearby ... kind of like a Markov chain, except in a Markov chain the probability of the next bit only depends on the _one_ immediately before, which is a pretty narrow notion of "nearby." To broaden that, you could define a _higher-order_ Markov chain, where the probability of the next bit depends on the previous _n_ bits for some specific value of _n_.

And _that's_ how you can explain mysteriously frequent consecutive runs and alternations. If the last _two_ bits being `01` (respectively `10`) makes it more likely for the next bit to be `0` (respectively `1`), _and_ the last two bits being `00` (respectively `11`) makes it more likely for the next bit to be `0` (respectively `1`), then you would be more likely to see long `0000`... or `1111`... consecutive runs _and_ `01010`... alternations.

A biased coin is just an _n_-th-order Markov chain where _n_ = 0. An _n_-th-order Markov chain where _n_ > 1, is just a first-order Markov chain where each "state" is a tuple of bits, rather than a single bit. Everything in the universe is a Markov chain!—with respect to the models you've considered so far.

[TODO diagram: directed graph illustrations of higher-order Markov chains]

"The bitstream is being generated by a Markov chain of some order" is _a_ theory, but a pretty broad one. To make it concrete enough to test, you'll want to posit some specific order _n_, and, given _n_, specific parameters for the next-bit-given-previous-_n_ probabilities. The _n_ = 0 coin has one parameter: the bias of the coin.

The _n_ = 1 ordinary Markov chain has two parameters: 

[TODO: the question of what order to pick is what motivates penalizing complex models: lower-order models are the same as higher-order models with the coefficients pinned (third-order such that 010==110 &c. is just second-order)]

[TODO: show code estimating the max-likelihood parameters, then compute naive "fit" likelihoods, then note that this is coming close to underflowing an f32 and take the logarithm (and talk about the logarithmic score), then express confusion as to how to pick _n_ (given that higher-order can always fit better), then use coding considerations to motivate the complexity penalty]

[_Intelligence is prediction is compression_.](https://www.lesswrong.com/posts/ex63DPisEjomutkCw/msg-len)

https://en.wikipedia.org/wiki/Texas_sharpshooter_fallacy
https://www.lesswrong.com/posts/H59YqogX94z5jb8xx/inductive-bias

[(Full source code.)](TODO)
